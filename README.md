# Image-caption-Generator-
Abstract
Humans easily understand images encountered daily, but machines require captions for generating automatic descriptions. Image captioning improves the accuracy of image search and indexing. Despite advances in object recognition, machines still struggle to produce human-like descriptions. This project aims to assist blind individuals by converting image descriptions into speech, promoting independent navigation.

# Introduction
How do human process image?
Generate caption and then generate description Same way machine process the image Object recognition and creating human like description
Creating Human like description â€“ challenging
Helps blind individuals navigate by describing surroundings through a smartphone app.
Enhances social media by automatically generating image captions.
Improves e-commerce by creating product descriptions from images.
Assists in organizing and searching photo collections automatically.

# Project Design
![image](https://github.com/akansha-sharma-28/Image-caption-Generator-/assets/106007341/cf07bd7f-39f5-4f9b-b5ac-52822d293c8c)


# Dataset
FLICKR8K DATASET
Flickr8k dataset is a public benchmark dataset for image to sentence description. This dataset consists of 8000 images with five captions for each image. These images are extracted from diverse groups in Flickr website.
The dataset has 6000 images in training dataset, 1000 images in development dataset and 1000 images in test dataset.
# Technology Used
# Python Libraries
1. TensorFlow/Keras: These are the primary frameworks used for building and 
   training the deep learning models. TensorFlow provides the backend 
   computational power, while Keras offers a user-friendly interface for d 
   designing and training neural networks.
2. OpenCV: This library is used for image processing tasks, such as reading 
   and writing images, and applying transformations like resizing and 
   cropping.
3. NumPy: Essential for numerical computations and handling 
   multidimensional arrays, which are integral to managing image and text 
   data.
4. Text-to-Speech (TTS)
   gTTS (Google Text-to-Speech): This library is used to convert the 
   generated captions into speech, enabling an auditory output for the 
   captions.
# Novelty
Understand the content of the image.
1. Turn the understanding of the image into words in proper order.
2. Convert Caption Text to speech.
3. Provide Caption in User preference language

# Result
![image](https://github.com/akansha-sharma-28/Image-caption-Generator-/assets/106007341/e843249f-4bde-4e46-b6d5-713cb05c784d)

![Picture1](https://github.com/akansha-sharma-28/Image-caption-Generator-/assets/106007341/95e7fe84-b89b-427b-ab37-a9e32bf463dd)

![image](https://github.com/akansha-sharma-28/Image-caption-Generator-/assets/106007341/330c9b01-bbf1-4943-bea5-1b4bbfab8415)


# Conclusion
The successful implementation of this project showcases the capability of AI to interpret visual content and translate it into coherent textual descriptions. This has significant implications for various applications, including assisting visually impaired individuals
Our model's integration with real-time translation services further broadens its usability, enabling caption generation in multiple languages and making the technology accessible to a global audience. 



